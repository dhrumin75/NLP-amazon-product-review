{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical 5 - Implementing LSA and Topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "e8KVMgDfbKF6",
    "outputId": "e2110c44-5cd2-406b-cf37-9266fa79bfd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dhrumin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# If nltk stop word is not downloaded\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Books : Sapiens and Homo Deus are certainly ey...</td>\n",
       "      <td>Books : Sapiens and Homo Deus are certainly ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thought provoking. Amazing way of raising cont...</td>\n",
       "      <td>Thought provoking. Amazing way of raising cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>An excellent account of some of the possible a...</td>\n",
       "      <td>An excellent account of some of the possible a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brilliant !. Another great book after Sapiens....</td>\n",
       "      <td>Brilliant !. Another great book after Sapiens....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Well this book will widen your perspective muc...</td>\n",
       "      <td>Well this book will widen your perspective muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Books : Sapiens and Homo Deus are certainly ey...</td>\n",
       "      <td>Books : Sapiens and Homo Deus are certainly ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thought provoking. Amazing way of raising cont...</td>\n",
       "      <td>Thought provoking. Amazing way of raising cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>An excellent account of some of the possible a...</td>\n",
       "      <td>An excellent account of some of the possible a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brilliant !. Another great book after Sapiens....</td>\n",
       "      <td>Brilliant !. Another great book after Sapiens....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Well this book will widen your perspective muc...</td>\n",
       "      <td>Well this book will widen your perspective muc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review  \\\n",
       "0   Boy am I glad I am living this day and age rat...   \n",
       "1   Enough is said about the book and the author.....   \n",
       "2   This is the most important book i read in last...   \n",
       "3   Same as it's predecessor this book also discus...   \n",
       "4   A must read in a lifetime !I took quite someti...   \n",
       "5   Books : Sapiens and Homo Deus are certainly ey...   \n",
       "6   Thought provoking. Amazing way of raising cont...   \n",
       "7   An excellent account of some of the possible a...   \n",
       "8   Brilliant !. Another great book after Sapiens....   \n",
       "9   Well this book will widen your perspective muc...   \n",
       "10  Boy am I glad I am living this day and age rat...   \n",
       "11  Enough is said about the book and the author.....   \n",
       "12  This is the most important book i read in last...   \n",
       "13  Same as it's predecessor this book also discus...   \n",
       "14  A must read in a lifetime !I took quite someti...   \n",
       "15  Books : Sapiens and Homo Deus are certainly ey...   \n",
       "16  Thought provoking. Amazing way of raising cont...   \n",
       "17  An excellent account of some of the possible a...   \n",
       "18  Brilliant !. Another great book after Sapiens....   \n",
       "19  Well this book will widen your perspective muc...   \n",
       "\n",
       "                                            documents  \n",
       "0   Boy am I glad I am living this day and age rat...  \n",
       "1   Enough is said about the book and the author.....  \n",
       "2   This is the most important book i read in last...  \n",
       "3   Same as it's predecessor this book also discus...  \n",
       "4   A must read in a lifetime !I took quite someti...  \n",
       "5   Books : Sapiens and Homo Deus are certainly ey...  \n",
       "6   Thought provoking. Amazing way of raising cont...  \n",
       "7   An excellent account of some of the possible a...  \n",
       "8   Brilliant !. Another great book after Sapiens....  \n",
       "9   Well this book will widen your perspective muc...  \n",
       "10  Boy am I glad I am living this day and age rat...  \n",
       "11  Enough is said about the book and the author.....  \n",
       "12  This is the most important book i read in last...  \n",
       "13  Same as it's predecessor this book also discus...  \n",
       "14  A must read in a lifetime !I took quite someti...  \n",
       "15  Books : Sapiens and Homo Deus are certainly ey...  \n",
       "16  Thought provoking. Amazing way of raising cont...  \n",
       "17  An excellent account of some of the possible a...  \n",
       "18  Brilliant !. Another great book after Sapiens....  \n",
       "19  Well this book will widen your perspective muc...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Homo Deus.csv',nrows=20)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['documents'] = df['Review']\n",
    "df = df.drop(['Name','Rating'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "bSuv4zhsbTgI",
    "outputId": "f1b6508f-be75-473b-b7de-ada50a633558"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He is a good dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog is too lazy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That is a brown cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The cat is very active.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have brown cat and dog.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   documents\n",
       "0          He is a good dog.\n",
       "1       The dog is too lazy.\n",
       "2       That is a brown cat.\n",
       "3    The cat is very active.\n",
       "4  I have brown cat and dog."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of documents\n",
    "a1 = \"He is a good dog.\"\n",
    "a2 = \"The dog is too lazy.\"\n",
    "a3 = \"That is a brown cat.\"\n",
    "a4 = \"The cat is very active.\"\n",
    "a5 = \"I have brown cat and dog.\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"documents\"] = [a1,a2,a3,a4,a5]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "wUxTyXEcbabc",
    "outputId": "e5a5d691-2d0f-46fd-c5ea-bf34c93b84cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>documents</th>\n",
       "      <th>clean_documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "      <td>boy glad living this day and age rather than y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "      <td>enough said about the book and the author all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "      <td>this the most important book read last five ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "      <td>same predecessor this book also discusses the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "      <td>must read lifetime took quite sometime read th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  Boy am I glad I am living this day and age rat...   \n",
       "1  Enough is said about the book and the author.....   \n",
       "2  This is the most important book i read in last...   \n",
       "3  Same as it's predecessor this book also discus...   \n",
       "4  A must read in a lifetime !I took quite someti...   \n",
       "\n",
       "                                           documents  \\\n",
       "0  Boy am I glad I am living this day and age rat...   \n",
       "1  Enough is said about the book and the author.....   \n",
       "2  This is the most important book i read in last...   \n",
       "3  Same as it's predecessor this book also discus...   \n",
       "4  A must read in a lifetime !I took quite someti...   \n",
       "\n",
       "                                     clean_documents  \n",
       "0  boy glad living this day and age rather than y...  \n",
       "1  enough said about the book and the author all ...  \n",
       "2  this the most important book read last five ye...  \n",
       "3  same predecessor this book also discusses the ...  \n",
       "4  must read lifetime took quite sometime read th...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df['clean_documents'] = df['documents'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "df['clean_documents'] = df['clean_documents'].fillna('').apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "df['clean_documents'] = df['clean_documents'].fillna('').apply(lambda x: x.lower())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oAh-g-Zvbwfq"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# tokenization\n",
    "tokenized_doc = df['clean_documents'].fillna('').apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words\n",
    "\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stopwords.words('english')])\n",
    "\n",
    "# de-tokenization\n",
    "detokenized_doc = []\n",
    "for i in range(len(df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "df['clean_documents'] = detokenized_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "blwhwUPyiEc5",
    "outputId": "4067a5c2-151c-4ff0-b282-389980336f91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>documents</th>\n",
       "      <th>clean_documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "      <td>Boy am I glad I am living this day and age rat...</td>\n",
       "      <td>boy glad living day age rather years coinciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "      <td>Enough is said about the book and the author.....</td>\n",
       "      <td>enough said book author tell imagination creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "      <td>This is the most important book i read in last...</td>\n",
       "      <td>important book read last five years traces con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "      <td>Same as it's predecessor this book also discus...</td>\n",
       "      <td>predecessor book also discusses workings logic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "      <td>A must read in a lifetime !I took quite someti...</td>\n",
       "      <td>must read lifetime took quite sometime read in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  Boy am I glad I am living this day and age rat...   \n",
       "1  Enough is said about the book and the author.....   \n",
       "2  This is the most important book i read in last...   \n",
       "3  Same as it's predecessor this book also discus...   \n",
       "4  A must read in a lifetime !I took quite someti...   \n",
       "\n",
       "                                           documents  \\\n",
       "0  Boy am I glad I am living this day and age rat...   \n",
       "1  Enough is said about the book and the author.....   \n",
       "2  This is the most important book i read in last...   \n",
       "3  Same as it's predecessor this book also discus...   \n",
       "4  A must read in a lifetime !I took quite someti...   \n",
       "\n",
       "                                     clean_documents  \n",
       "0  boy glad living day age rather years coinciden...  \n",
       "1  enough said book author tell imagination creat...  \n",
       "2  important book read last five years traces con...  \n",
       "3  predecessor book also discusses workings logic...  \n",
       "4  must read lifetime took quite sometime read in...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "jbyV4FVViHWg",
    "outputId": "72009c9a-f987-4306-ca8c-f13795f158af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12901236, 0.        , 0.        , ..., 0.08090004, 0.09190604,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.14305868,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.11940667, ..., 0.07487658, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.2996879 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF vector\n",
    "vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
    "X = vectorizer.fit_transform(df['clean_documents'])\n",
    "X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_o2W2SKJLj1B",
    "outputId": "1de0c9af-0a00-4477-8b23-2d9e0a713f1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 247)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape \n",
    "# A56   U(5,5). S()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zN-Q4IGlj2i"
   },
   "outputs": [],
   "source": [
    "# SVD represent documents and terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100, random_state=122)\n",
    "lsa = svd_model.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "rBK9p0Wulkw4",
    "outputId": "796d6268-b815-41a4-88a1-4f114514710d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boy glad living day age rather years coinciden...</td>\n",
       "      <td>0.3981256762048849</td>\n",
       "      <td>0.6071657987895401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enough said book author tell imagination creat...</td>\n",
       "      <td>0.3046843686696321</td>\n",
       "      <td>-0.3064528505157263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>important book read last five years traces con...</td>\n",
       "      <td>0.4340933394847125</td>\n",
       "      <td>-0.2452355154812578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>predecessor book also discusses workings logic...</td>\n",
       "      <td>0.5234837166997298</td>\n",
       "      <td>-0.2959380524831141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>must read lifetime took quite sometime read in...</td>\n",
       "      <td>0.3508617181115348</td>\n",
       "      <td>-0.1624887605701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>books sapiens homo deus certainly eye openers ...</td>\n",
       "      <td>0.3109437675653213</td>\n",
       "      <td>0.5586301837503166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>thought provoking amazing way raising controve...</td>\n",
       "      <td>0.2733668456164287</td>\n",
       "      <td>0.2041781165484859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>excellent account possible plausible scenarios...</td>\n",
       "      <td>0.4113174200673417</td>\n",
       "      <td>-0.3002215311670962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>brilliant another great book sapiens excellent...</td>\n",
       "      <td>0.4938932434627802</td>\n",
       "      <td>-0.0831711147592769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>well book widen perspective much like homo sap...</td>\n",
       "      <td>0.4233403299919939</td>\n",
       "      <td>0.2482020455975403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>boy glad living day age rather years coinciden...</td>\n",
       "      <td>0.3981256762048850</td>\n",
       "      <td>0.6071657987895399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>enough said book author tell imagination creat...</td>\n",
       "      <td>0.3046843686696321</td>\n",
       "      <td>-0.3064528505157261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>important book read last five years traces con...</td>\n",
       "      <td>0.4340933394847125</td>\n",
       "      <td>-0.2452355154812582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>predecessor book also discusses workings logic...</td>\n",
       "      <td>0.5234837166997298</td>\n",
       "      <td>-0.2959380524831136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>must read lifetime took quite sometime read in...</td>\n",
       "      <td>0.3508617181115348</td>\n",
       "      <td>-0.1624887605701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>books sapiens homo deus certainly eye openers ...</td>\n",
       "      <td>0.3109437675653213</td>\n",
       "      <td>0.5586301837503166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>thought provoking amazing way raising controve...</td>\n",
       "      <td>0.2733668456164287</td>\n",
       "      <td>0.2041781165484859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>excellent account possible plausible scenarios...</td>\n",
       "      <td>0.4113174200673417</td>\n",
       "      <td>-0.3002215311670962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>brilliant another great book sapiens excellent...</td>\n",
       "      <td>0.4938932434627802</td>\n",
       "      <td>-0.0831711147592769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>well book widen perspective much like homo sap...</td>\n",
       "      <td>0.4233403299919939</td>\n",
       "      <td>0.2482020455975403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            documents            topic_1  \\\n",
       "0   boy glad living day age rather years coinciden... 0.3981256762048849   \n",
       "1   enough said book author tell imagination creat... 0.3046843686696321   \n",
       "2   important book read last five years traces con... 0.4340933394847125   \n",
       "3   predecessor book also discusses workings logic... 0.5234837166997298   \n",
       "4   must read lifetime took quite sometime read in... 0.3508617181115348   \n",
       "5   books sapiens homo deus certainly eye openers ... 0.3109437675653213   \n",
       "6   thought provoking amazing way raising controve... 0.2733668456164287   \n",
       "7   excellent account possible plausible scenarios... 0.4113174200673417   \n",
       "8   brilliant another great book sapiens excellent... 0.4938932434627802   \n",
       "9   well book widen perspective much like homo sap... 0.4233403299919939   \n",
       "10  boy glad living day age rather years coinciden... 0.3981256762048850   \n",
       "11  enough said book author tell imagination creat... 0.3046843686696321   \n",
       "12  important book read last five years traces con... 0.4340933394847125   \n",
       "13  predecessor book also discusses workings logic... 0.5234837166997298   \n",
       "14  must read lifetime took quite sometime read in... 0.3508617181115348   \n",
       "15  books sapiens homo deus certainly eye openers ... 0.3109437675653213   \n",
       "16  thought provoking amazing way raising controve... 0.2733668456164287   \n",
       "17  excellent account possible plausible scenarios... 0.4113174200673417   \n",
       "18  brilliant another great book sapiens excellent... 0.4938932434627802   \n",
       "19  well book widen perspective much like homo sap... 0.4233403299919939   \n",
       "\n",
       "               topic_2  \n",
       "0   0.6071657987895401  \n",
       "1  -0.3064528505157263  \n",
       "2  -0.2452355154812578  \n",
       "3  -0.2959380524831141  \n",
       "4  -0.1624887605701900  \n",
       "5   0.5586301837503166  \n",
       "6   0.2041781165484859  \n",
       "7  -0.3002215311670962  \n",
       "8  -0.0831711147592769  \n",
       "9   0.2482020455975403  \n",
       "10  0.6071657987895399  \n",
       "11 -0.3064528505157261  \n",
       "12 -0.2452355154812582  \n",
       "13 -0.2959380524831136  \n",
       "14 -0.1624887605701900  \n",
       "15  0.5586301837503166  \n",
       "16  0.2041781165484859  \n",
       "17 -0.3002215311670962  \n",
       "18 -0.0831711147592769  \n",
       "19  0.2482020455975403  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Documents - Topic vector\n",
    "pd.options.display.float_format = '{:,.16f}'.format\n",
    "topic_encoded_df = pd.DataFrame(lsa, columns = [\"topic_1\", \"topic_2\"])\n",
    "topic_encoded_df[\"documents\"] = df['clean_documents']\n",
    "display(topic_encoded_df[[\"documents\", \"topic_1\", \"topic_2\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77yIqTbemFk3"
   },
   "outputs": [],
   "source": [
    "# Features or words used as features \n",
    "dictionary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SN2uU8AQmX-k",
    "outputId": "dd102656-d1d5-4bbf-a642-a02b91c306e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accelerating',\n",
       " 'according',\n",
       " 'account',\n",
       " 'added',\n",
       " 'advances',\n",
       " 'advise',\n",
       " 'age',\n",
       " 'algorithm',\n",
       " 'amazing',\n",
       " 'analysis',\n",
       " 'answer',\n",
       " 'articles',\n",
       " 'articulately',\n",
       " 'artificial',\n",
       " 'asks',\n",
       " 'atheist',\n",
       " 'author',\n",
       " 'away',\n",
       " 'babies',\n",
       " 'based',\n",
       " 'behavior',\n",
       " 'better',\n",
       " 'bible',\n",
       " 'bio',\n",
       " 'black',\n",
       " 'blows',\n",
       " 'book',\n",
       " 'books',\n",
       " 'bow',\n",
       " 'boy',\n",
       " 'brain',\n",
       " 'breadth',\n",
       " 'brilliant',\n",
       " 'buy',\n",
       " 'came',\n",
       " 'canvas',\n",
       " 'certainly',\n",
       " 'challenged',\n",
       " 'cheers',\n",
       " 'children',\n",
       " 'chilled',\n",
       " 'choose',\n",
       " 'clarity',\n",
       " 'clear',\n",
       " 'clumps',\n",
       " 'coincidence',\n",
       " 'combined',\n",
       " 'coming',\n",
       " 'completely',\n",
       " 'concepts',\n",
       " 'conferences',\n",
       " 'confused',\n",
       " 'confusion',\n",
       " 'contemporary',\n",
       " 'controversial',\n",
       " 'convincingly',\n",
       " 'copy',\n",
       " 'created',\n",
       " 'creative',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'day',\n",
       " 'deathwish',\n",
       " 'decrbed',\n",
       " 'definition',\n",
       " 'delivery',\n",
       " 'designer',\n",
       " 'deus',\n",
       " 'different',\n",
       " 'discuss',\n",
       " 'discusses',\n",
       " 'dissolving',\n",
       " 'disturbing',\n",
       " 'dont',\n",
       " 'driven',\n",
       " 'easy',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'engineering',\n",
       " 'enjoyed',\n",
       " 'enriched',\n",
       " 'evolution',\n",
       " 'excellent',\n",
       " 'exciting',\n",
       " 'existence',\n",
       " 'expanded',\n",
       " 'expanse',\n",
       " 'extinct',\n",
       " 'eye',\n",
       " 'farfetched',\n",
       " 'flow',\n",
       " 'future',\n",
       " 'gain',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'glad',\n",
       " 'good',\n",
       " 'grandchildren',\n",
       " 'great',\n",
       " 'gripping',\n",
       " 'hacking',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happinesses',\n",
       " 'harari',\n",
       " 'healthy',\n",
       " 'historic',\n",
       " 'homo',\n",
       " 'human',\n",
       " 'humanity',\n",
       " 'humans',\n",
       " 'imagination',\n",
       " 'important',\n",
       " 'incremental',\n",
       " 'indeniable',\n",
       " 'information',\n",
       " 'intelligence',\n",
       " 'intelligent',\n",
       " 'intend',\n",
       " 'journals',\n",
       " 'kingdom',\n",
       " 'know',\n",
       " 'knowledge',\n",
       " 'leaves',\n",
       " 'life',\n",
       " 'lifetime',\n",
       " 'like',\n",
       " 'living',\n",
       " 'logic',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lucidly',\n",
       " 'mad',\n",
       " 'magic',\n",
       " 'makes',\n",
       " 'manner',\n",
       " 'masterpiece',\n",
       " 'matter',\n",
       " 'mean',\n",
       " 'mid',\n",
       " 'mind',\n",
       " 'mirror',\n",
       " 'miss',\n",
       " 'mix',\n",
       " 'modify',\n",
       " 'mud',\n",
       " 'narrative',\n",
       " 'nature',\n",
       " 'navigate',\n",
       " 'near',\n",
       " 'netflix',\n",
       " 'new',\n",
       " 'noah',\n",
       " 'oblivion',\n",
       " 'openers',\n",
       " 'order',\n",
       " 'original',\n",
       " 'overwhelming',\n",
       " 'papers',\n",
       " 'past',\n",
       " 'people',\n",
       " 'perspective',\n",
       " 'perspectives',\n",
       " 'plausible',\n",
       " 'points',\n",
       " 'ponders',\n",
       " 'possibilities',\n",
       " 'possibility',\n",
       " 'possible',\n",
       " 'practitioner',\n",
       " 'predecessor',\n",
       " 'present',\n",
       " 'presented',\n",
       " 'probable',\n",
       " 'problems',\n",
       " 'process',\n",
       " 'prof',\n",
       " 'proof',\n",
       " 'providing',\n",
       " 'provoking',\n",
       " 'puts',\n",
       " 'quality',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quite',\n",
       " 'raising',\n",
       " 'range',\n",
       " 'read',\n",
       " 'reading',\n",
       " 'reads',\n",
       " 'redundant',\n",
       " 'references',\n",
       " 'regimes',\n",
       " 'religion',\n",
       " 'religious',\n",
       " 'researched',\n",
       " 'right',\n",
       " 'river',\n",
       " 'rush',\n",
       " 'said',\n",
       " 'sapiens',\n",
       " 'scary',\n",
       " 'scenarios',\n",
       " 'season',\n",
       " 'sense',\n",
       " 'shadows',\n",
       " 'shall',\n",
       " 'shape',\n",
       " 'society',\n",
       " 'solution',\n",
       " 'stand',\n",
       " 'store',\n",
       " 'study',\n",
       " 'style',\n",
       " 'systems',\n",
       " 'technological',\n",
       " 'technology',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thoroughly',\n",
       " 'thought',\n",
       " 'throw',\n",
       " 'time',\n",
       " 'today',\n",
       " 'took',\n",
       " 'topics',\n",
       " 'touched',\n",
       " 'traces',\n",
       " 'true',\n",
       " 'understand',\n",
       " 'unpredictable',\n",
       " 'view',\n",
       " 'views',\n",
       " 'vipassana',\n",
       " 'wasted',\n",
       " 'watch',\n",
       " 'way',\n",
       " 'wide',\n",
       " 'widen',\n",
       " 'wondering',\n",
       " 'work',\n",
       " 'workings',\n",
       " 'world',\n",
       " 'years',\n",
       " 'yuval']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndd5hK6wmbXV"
   },
   "outputs": [],
   "source": [
    "# Term-Topic matrix\n",
    "encoding_matrix = pd.DataFrame(svd_model.components_, index = [\"topic_1\",\"topic_2\"], columns = (dictionary)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "1pTPu0xdmjAp",
    "outputId": "0a50b3fc-c15f-485c-acbb-9f9e95db5fb4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accelerating</th>\n",
       "      <td>0.0320887645936997</td>\n",
       "      <td>0.0681682105192582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>according</th>\n",
       "      <td>0.0792611445968919</td>\n",
       "      <td>0.0647318226529338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>account</th>\n",
       "      <td>0.0306836622782651</td>\n",
       "      <td>-0.0311970630042577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>added</th>\n",
       "      <td>0.0391652019610703</td>\n",
       "      <td>-0.0548726134674279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advances</th>\n",
       "      <td>0.0306836622782651</td>\n",
       "      <td>-0.0311970630042577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.0276126617896151</td>\n",
       "      <td>0.0287285303036194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workings</th>\n",
       "      <td>0.0847435629372862</td>\n",
       "      <td>-0.0667338432917115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.0827310620441177</td>\n",
       "      <td>0.1063978525443479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>0.0951514753118973</td>\n",
       "      <td>-0.0035769135759157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yuval</th>\n",
       "      <td>0.0470182933999204</td>\n",
       "      <td>-0.0303316464731626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        topic_1             topic_2\n",
       "accelerating 0.0320887645936997  0.0681682105192582\n",
       "according    0.0792611445968919  0.0647318226529338\n",
       "account      0.0306836622782651 -0.0311970630042577\n",
       "added        0.0391652019610703 -0.0548726134674279\n",
       "advances     0.0306836622782651 -0.0311970630042577\n",
       "...                         ...                 ...\n",
       "work         0.0276126617896151  0.0287285303036194\n",
       "workings     0.0847435629372862 -0.0667338432917115\n",
       "world        0.0827310620441177  0.1063978525443479\n",
       "years        0.0951514753118973 -0.0035769135759157\n",
       "yuval        0.0470182933999204 -0.0303316464731626\n",
       "\n",
       "[247 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMIaiN6mmkvN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
